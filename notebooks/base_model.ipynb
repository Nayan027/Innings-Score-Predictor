{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8316025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as nayanparvez90\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as nayanparvez90\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"nayanparvez90/Innings-Score-Predictor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"nayanparvez90/Innings-Score-Predictor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository nayanparvez90/Innings-Score-Predictor initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository nayanparvez90/Innings-Score-Predictor initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 13:13:40 INFO mlflow.tracking.fluent: Experiment with name 'Base Regression Model' does not exist. Creating a new experiment.\n",
      "2025/04/11 13:13:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/04/11 13:13:56 INFO mlflow.tracking._tracking_service.client: 🏃 View run enchanting-ant-938 at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/3/runs/951853f629844229aac925e41132c104.\n",
      "2025/04/11 13:13:56 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/3.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "# =========================== Data Preprocessing Functions ====================================\n",
    "\n",
    "def remove_unwanted_columns(df, columns_to_remove):\n",
    "    \"\"\"Removes specified columns from the DataFrame.\"\"\"\n",
    "    return df.drop(labels=columns_to_remove, axis=1)\n",
    "\n",
    "def filter_consistent_teams(df, consistent_teams):\n",
    "    \"\"\"Filters data to keep only matches with consistent teams.\"\"\"\n",
    "    return df[(df['bat_team'].isin(consistent_teams)) & (df['bowl_team'].isin(consistent_teams))]\n",
    "\n",
    "def remove_initial_overs(df, min_overs=4.1):\n",
    "    \"\"\"Removes data for the first few overs in each match.\"\"\"\n",
    "    return df[df['overs'] >= min_overs]\n",
    "\n",
    "def convert_date_column(df):\n",
    "    \"\"\"Converts 'date' column from string to datetime object.\"\"\"\n",
    "    df['date'] = df['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "    return df\n",
    "\n",
    "# Complete Preprocessing Pipeline\n",
    "def preprocess_raw_data(df):\n",
    "    \"\"\"Applies all preprocessing steps to clean and prepare the dataset for training and inference.\"\"\"\n",
    "    columns_to_remove = ['mid', 'venue', 'batsman', 'bowler','striker', 'non-striker']  \n",
    "\n",
    "    consistent_teams = ['Kolkata Knight Riders', 'Chennai Super Kings', 'Rajasthan Royals',\n",
    "                        'Mumbai Indians', 'Kings XI Punjab', 'Royal Challengers Bangalore',\n",
    "                        'Delhi Daredevils', 'Sunrisers Hyderabad']\n",
    "    \n",
    "    df = convert_date_column(df)                     \n",
    "    df = remove_unwanted_columns(df, columns_to_remove)\n",
    "    df = filter_consistent_teams(df, consistent_teams)\n",
    "    df = remove_initial_overs(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "#============================== Feature Engineering Function =====================================\n",
    "\n",
    "# Create a global scaler so it can be used across train/test\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scaling function\n",
    "def scale_numerical_features(df, numerical_columns, fit_scaler=False):\n",
    "    \"\"\"\n",
    "    Scale numerical features using StandardScaler.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: input DataFrame\n",
    "    - numerical_columns: list of column names to scale\n",
    "    - fit_scaler: if True, fits the scaler; otherwise, transforms using already fit scaler\n",
    "    \n",
    "    Returns:\n",
    "    - Scaled DataFrame\n",
    "    \"\"\"\n",
    "    if fit_scaler:\n",
    "        df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    else:\n",
    "        df[numerical_columns] = scaler.transform(df[numerical_columns])\n",
    "    return df\n",
    "\n",
    "# encoding function\n",
    "def encode_categorical_features(df, categorical_columns):\n",
    "    \"\"\"Apply one-hot encoding to categorical columns.\"\"\"\n",
    "    return pd.get_dummies(data=df, columns=categorical_columns)\n",
    "\n",
    "# Complete Feature Engineering Pipeline\n",
    "def apply_feature_engineering(df, fit_scaler=False):\n",
    "    \"\"\"\n",
    "    Apply full feature engineering: encoding + scaling.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: input DataFrame\n",
    "    - fit_scaler: True for training data, False for test data\n",
    "    \n",
    "    Returns:\n",
    "    - Processed DataFrame\n",
    "    \"\"\"\n",
    "    categorical_columns = ['bat_team', 'bowl_team']\n",
    "    numerical_columns = ['overs', 'runs', 'wickets','runs_last_5', 'wickets_last_5']\n",
    "    \n",
    "    df = encode_categorical_features(df, categorical_columns)\n",
    "    df = scale_numerical_features(df, numerical_columns, fit_scaler=fit_scaler)\n",
    "    return df\n",
    "\n",
    "\n",
    "#================================== Model Training and Evaluation ================================\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Trains a Linear Regression model.\"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluates the model and logs metrics.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "    \n",
    "    logging.info(f\"Model Evaluation: MAE={mae}, MSE={mse}, R2-Score={r2}\")\n",
    "    return mae, mse, r2\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data.csv')\n",
    "df = preprocess_raw_data(df)                           # Preprocessing raw data\n",
    "\n",
    "'''Saving the preprocessed data to a new CSV file which we'll later use for our ease when we'll be tuning the best algorithm'''\n",
    "\n",
    "df.to_csv(\"preprocessed_data.csv\", index=False)\n",
    "logging.info(\"Preprocessed data saved as 'preprocessed_data.csv' for future use.\")\n",
    "\n",
    "# Split using date (no random split coz its time-series-like usecase)\n",
    "train_df = df[df['date'].dt.year <= 2015].copy()\n",
    "test_df = df[df['date'].dt.year >= 2016].copy()\n",
    "\n",
    "# Drop target column\n",
    "X_train = train_df.drop(columns=['total'])\n",
    "y_train = train_df['total']\n",
    "\n",
    "X_test = test_df.drop(columns=['total'])\n",
    "y_test = test_df['total']\n",
    "\n",
    "# Drop 'date' before encoding\n",
    "if 'date' in X_train.columns:\n",
    "    X_train = X_train.drop(columns='date') \n",
    "if 'date' in X_test.columns:                 # the best time to drop the date column is after splitting and before feature engg.\n",
    "    X_test = X_test.drop(columns='date')\n",
    "\n",
    "\n",
    "# Feature Engineering applied separately to train and test\n",
    "X_train = apply_feature_engineering(X_train, fit_scaler=True)      # fits and transforms train data\n",
    "X_test = apply_feature_engineering(X_test, fit_scaler=False)       # only transforms test data\n",
    "\n",
    "# Align columns of test set to match train set (fixing dummy mismatch)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_tracking_uri('https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow')\n",
    "dagshub.init(repo_owner='nayanparvez90', repo_name='Innings-Score-Predictor', mlflow=True)\n",
    "\n",
    "\n",
    "# mlflow.set_experiment\n",
    "mlflow.set_experiment(\"Base Regression Model\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "    # Calculate and log year ranges from the original DataFrame\n",
    "    train_years = f\"{train_df['date'].dt.year.min()}-{train_df['date'].dt.year.max()}\"\n",
    "    test_years = f\"{test_df['date'].dt.year.min()}-{test_df['date'].dt.year.max()}\"\n",
    "\n",
    "    mlflow.log_param(\"train_years\", train_years)\n",
    "    mlflow.log_param(\"test_years\", test_years)\n",
    "    \n",
    "    mlflow.log_param(\"model\", \"Linear Regression\")\n",
    "    mlflow.log_param(\"test_size\", 'roughly about ~0.27')\n",
    "    \n",
    "    logging.info(\"Training the model...\")\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    logging.info(\"Evaluating the model...\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    logging.info(\"Logging model to MLflow...\")\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    logging.info(\"MLflow run completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e34fed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7412696b",
   "metadata": {},
   "source": [
    "### On deletion of an experiment in mlflow an error as such might occur:\n",
    "\n",
    "\n",
    "- MlflowException: Cannot set a deleted experiment 'Hyperparameter Tuning Experiment' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.\n",
    "\n",
    "- Here, MlflowException suggests that the experiment \"Hyperparameter Tuning Experiment\" was deleted and is now in a deleted state in MLflow's backend. This prevents it from being set as the active experiment.\n",
    "\n",
    "- Here's how we fix if an exception as such occurs for us.\n",
    "\n",
    "\n",
    "### Step 1: Check for Deleted Experiments\n",
    "\n",
    "use the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb079d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "\n",
    "# client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# # Get deleted experiments\n",
    "# deleted_experiments = [exp for exp in client.search_experiments() if exp.lifecycle_stage == \"deleted\"]\n",
    "\n",
    "# # Print results in the notebook\n",
    "# if deleted_experiments:\n",
    "#     print(\"Deleted Experiments Found:\")\n",
    "#     for exp in deleted_experiments:\n",
    "#         print(f\" Name: {exp.name} | ID: {exp.experiment_id}\")\n",
    "# else:\n",
    "#     print(\" No deleted experiments found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c1215",
   "metadata": {},
   "source": [
    "If the experiment appears in the output, proceed to Step 2.\n",
    "### Step 2: Restore the Deleted Experiment\n",
    "If the experiment exists but is deleted, restore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30315d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# experiment_id = \"3\"                         # Replace with the actual experiment ID from Step 1\n",
    "# client.restore_experiment(experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6541259",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d270e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as nayanparvez90\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as nayanparvez90\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:57:23,463 - INFO - Accessing as nayanparvez90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"nayanparvez90/Innings-Score-Predictor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"nayanparvez90/Innings-Score-Predictor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:57:33,674 - INFO - Initialized MLflow to track repo \"nayanparvez90/Innings-Score-Predictor\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository nayanparvez90/Innings-Score-Predictor initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository nayanparvez90/Innings-Score-Predictor initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:57:33,679 - INFO - Repository nayanparvez90/Innings-Score-Predictor initialized!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 12:57:43 INFO mlflow.tracking.fluent: Experiment with name 'Best Model Selection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:58:01,864 - INFO - Size of dataframe before preprocessing: 76014\n",
      "2025-04-11 12:58:02,664 - INFO - Applied all the necessary preprocessing steps\n",
      "2025-04-11 12:58:02,664 - INFO - Size of dataframe after preprocessing: 42812\n",
      "2025-04-11 12:58:02,664 - INFO - This decrease in data size is because we've reduced data for the first few overs of each innings\n",
      "2025-04-11 12:58:02,664 - INFO - Entered training and evaluation method\n",
      "2025-04-11 12:58:03,399 - INFO - Splitting dataframe into train and test sets\n",
      "2025-04-11 12:58:03,436 - INFO - Applied Feature Engineering separately to train and test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algorithm: LinearRegression\n",
      "Metrics: {'r2_score': 0.6823818232428203, 'mae': 12.75853969035791, 'mse': 283.564297872011, 'mape': 0.08293583582718538}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 12:58:22 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run LinearRegression at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1/runs/645e4b36beef4df68a74b377a3ca9d16.\n",
      "2025/04/11 12:58:22 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1.\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algorithm: RidgeRegression\n",
      "Metrics: {'r2_score': 0.6823613616719547, 'mae': 12.758456355064027, 'mse': 283.5825656268199, 'mape': 0.0829356029399067}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 12:58:47 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run RidgeRegression at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1/runs/be5d1ce233ec4a84a3ab9cacc8423e0d.\n",
      "2025/04/11 12:58:47 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1.\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algorithm: LassoRegression\n",
      "Metrics: {'r2_score': 0.6837391055684274, 'mae': 12.683223474910529, 'mse': 282.3525384771161, 'mape': 0.08269908038888958}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 12:59:11 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run LassoRegression at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1/runs/029da3cf19c645aaa9279725429c74b1.\n",
      "2025/04/11 12:59:11 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1.\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algorithm: RandomForest\n",
      "Metrics: {'r2_score': 0.6529555305207221, 'mae': 13.354333326867867, 'mse': 309.83560929351466, 'mape': 0.08527552134076938}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 12:59:38 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run RandomForest at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1/runs/ed4e57ca982f49d2987130c426b8f71e.\n",
      "2025/04/11 12:59:38 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1.\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algorithm: XGBoost\n",
      "Metrics: {'r2_score': 0.6310387849807739, 'mae': 13.933145093933694, 'mse': 329.4025271133268, 'mape': 0.0885137345286565}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 13:00:02 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run XGBoost at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1/runs/f236b400b5db4817b9a100d70227b28a.\n",
      "2025/04/11 13:00:02 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:00:03,036 - INFO - Best model: Lasso with R2 score: 0.6837391055684274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 13:00:14 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/04/11 13:00:15 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run Best Model selector at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1/runs/4cb4d448db564261a4def8cf19e37fea.\n",
      "2025/04/11 13:00:15 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:00:15,634 - INFO - Training and evaluation completed.\n"
     ]
    }
   ],
   "source": [
    "# selecting best ml-algorithm for our regression use-case\n",
    "\n",
    "import mlflow\n",
    "import dagshub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import (r2_score, \n",
    "                            mean_absolute_error, \n",
    "                            mean_squared_error,\n",
    "                            mean_absolute_percentage_error)\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==================================== CONFIGURE LOGGING ==============================\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True)\n",
    "\n",
    "# =========================== CONFIGURATION =================================\n",
    "\n",
    "CONFIG = {\n",
    "    \"data_path\": \"data.csv\",\n",
    "    \"mlflow_tracking_uri\": \"https://dagshub.com/nayanparvez90/Innings-Score-Predictor.mlflow\",\n",
    "    \"dagshub_repo_owner\": \"nayanparvez90\",\n",
    "    \"dagshub_repo_name\": 'Innings-Score-Predictor',\n",
    "    \"experiment_name\": \"Best Model Selection\"\n",
    "}\n",
    "\n",
    "\n",
    "# ========================== SETUP MLflow & DAGSHUB ==========================\n",
    "\n",
    "mlflow.set_tracking_uri(CONFIG[\"mlflow_tracking_uri\"])\n",
    "dagshub.init(repo_owner=CONFIG[\"dagshub_repo_owner\"], repo_name=CONFIG[\"dagshub_repo_name\"], mlflow=True)\n",
    "mlflow.set_experiment(CONFIG[\"experiment_name\"])\n",
    "\n",
    "\n",
    "\n",
    "# ========================== Preprocessing Steps ==========================\n",
    "\n",
    "def remove_unwanted_columns(df):\n",
    "    columns_to_remove = ['mid','venue', 'batsman', 'bowler', 'striker', 'non-striker']\n",
    "    try:\n",
    "        df = df.drop(labels=columns_to_remove, axis=1)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing columns: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def convert_date_column(df):\n",
    "    try:\n",
    "        df['date'] = df['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting 'date' column: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def filter_consistent_teams(df):\n",
    "    consistent_teams = ['Kolkata Knight Riders', 'Chennai Super Kings', 'Rajasthan Royals',\n",
    "                        'Mumbai Indians', 'Kings XI Punjab', 'Royal Challengers Bangalore',\n",
    "                        'Delhi Daredevils', 'Sunrisers Hyderabad']\n",
    "    try:\n",
    "        df = df[(df['bat_team'].isin(consistent_teams)) & (df['bowl_team'].isin(consistent_teams))]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error filtering teams: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def remove_initial_overs(df, min_overs=4.1):\n",
    "    try:\n",
    "        df = df[df['overs'] >= min_overs]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing initial few overs: {e}\")\n",
    "        raise\n",
    "\n",
    "# ================================== Preprocessing Pipeline =============================\n",
    "\n",
    "def preprocess_df(df):\n",
    "    try:\n",
    "        df = convert_date_column(df)\n",
    "        df = remove_unwanted_columns(df)\n",
    "        df = filter_consistent_teams(df)\n",
    "        df = remove_initial_overs(df)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred in preprocessing step: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# ============================ Feature Engineering Steps ================================= \n",
    "\n",
    "# scaling numerical-features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def scale_numerical_features(df, numerical_columns, fit_scaler=False):\n",
    "    try:\n",
    "        if fit_scaler:\n",
    "            df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "        else:\n",
    "            df[numerical_columns] = scaler.transform(df[numerical_columns])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error scaling numerical features: {e}\")\n",
    "        raise\n",
    "\n",
    "# encoding categorical-features\n",
    "def encode_categorical_features(df, categorical_columns):\n",
    "    try:\n",
    "        df = pd.get_dummies(data=df, columns=categorical_columns)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding categorical feature: {e}\")\n",
    "        raise\n",
    "\n",
    "# ================================== Feature Engineering Pipeline ===============================\n",
    "\n",
    "def apply_feature_engineering(df, fit_scaler=False):\n",
    "    numerical_columns = ['overs', 'runs', 'wickets', 'runs_last_5', 'wickets_last_5']\n",
    "    categorical_columns = ['bat_team', 'bowl_team']\n",
    "\n",
    "    try:\n",
    "        df = encode_categorical_features(df, categorical_columns)\n",
    "        df = scale_numerical_features(df,numerical_columns, fit_scaler=fit_scaler)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature engg. step: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# ========================== LOAD DATA & APPLYING PREPROCESSING STEPS ==========================\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        logging.info(f\"Size of dataframe before preprocessing: {len(df)}\")\n",
    "\n",
    "\n",
    "        df = preprocess_df(df)\n",
    "        logging.info(\"Applied all the necessary preprocessing steps\")\n",
    "        logging.info(f\"Size of dataframe after preprocessing: {len(df)}\")\n",
    "        logging.info(\"This decrease in data size is because we've reduced data for the first few overs of each innings\")\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        logging.error(f\"Exception occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# =================================== DEFINING Regression ALGORITHMS ================================\n",
    "\n",
    "ALGORITHMS = {\n",
    "    'LinearRegression': LinearRegression(fit_intercept=True, n_jobs=5),\n",
    "    'RidgeRegression': Ridge(alpha=1.0, solver='auto', random_state=42),\n",
    "    'LassoRegression': Lasso(alpha=0.1, max_iter=1000, tol=0.0001),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_leaf=1, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# ========================= TRAINING & MODEL EVALUATION ==========================\n",
    "\n",
    "'''Set to distinguish and store Best model and it's params and results.'''\n",
    "best_score = float('-inf')                                       # Initializing with a very low score\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "def train_and_evaluate(df):\n",
    "    global best_score, best_model, best_params                   # specifying the global variables created.\n",
    "    logging.info(\"Entered training and evaluation method\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Best Model selector\") as parent_run:\n",
    "        \n",
    "        # Split using date (no random split)\n",
    "        train_df = df[df['date'].dt.year <= 2015].copy()\n",
    "        test_df = df[df['date'].dt.year >= 2016].copy()\n",
    "\n",
    "        # Drop target column and split further into X & y / train & test sets\n",
    "        X_train = train_df.drop(columns=['total'])\n",
    "        y_train = train_df['total']\n",
    "\n",
    "        X_test = test_df.drop(columns=['total'])\n",
    "        y_test = test_df['total']\n",
    "        logging.info(\"Splitting dataframe into train and test sets\")\n",
    "\n",
    "        # Drop 'date' before encoding\n",
    "        if 'date' in X_train.columns:\n",
    "            X_train = X_train.drop(columns='date') \n",
    "        if 'date' in X_test.columns:                    # the best time to drop the date column is after splitting and before feature engg.\n",
    "            X_test = X_test.drop(columns='date')\n",
    "\n",
    "\n",
    "        # Feature Engineering applied separately to train and test\n",
    "        X_train = apply_feature_engineering(X_train, fit_scaler=True)               # fits and transforms train data\n",
    "        X_test = apply_feature_engineering(X_test, fit_scaler=False)                # only transforms test data\n",
    "\n",
    "        # Align columns of test set to match train set (fixing dummy mismatch)\n",
    "        X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "        logging.info(\"Applied Feature Engineering separately to train and test\")\n",
    "\n",
    "\n",
    "        for algo_name, algorithm in ALGORITHMS.items():\n",
    "            with mlflow.start_run(run_name=f\"{algo_name}\", nested=True) as child_run:\n",
    "                try:\n",
    "                    # Log the algorithm name explicitly\n",
    "                    mlflow.log_param(\"algorithm\", algo_name)\n",
    "                    \n",
    "                    # Train model\n",
    "                    model = algorithm\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "                    # Log model parameters\n",
    "                    log_model_params(algo_name, model)\n",
    "\n",
    "                    # Predictions\n",
    "                    y_pred = model.predict(X_test)\n",
    "\n",
    "                    # Model Evaluation\n",
    "                    metrics = {\n",
    "    \"r2_score\": r2_score(y_test, y_pred),                      # Measures how well predictions match actual values (higher is better)\n",
    "    \"mae\": mean_absolute_error(y_test, y_pred),                                            # Average absolute error (lower is better)\n",
    "    \"mse\": mean_squared_error(y_test, y_pred),                                            # Penalizes larger errors (lower is better)\n",
    "    \"mape\": mean_absolute_percentage_error(y_test, y_pred),                    # Measures relative percentage error (lower is better)\n",
    "}\n",
    "\n",
    "                    mlflow.log_metrics(metrics)    # Logging metrics\n",
    "\n",
    "                    # Checks each model for the best one\n",
    "                    if metrics[\"r2_score\"] > best_score:\n",
    "                        best_score = metrics[\"r2_score\"]\n",
    "                        best_model = model\n",
    "                        best_params = model.get_params()       # Store the best model's params\n",
    "\n",
    "                    # Logging model\n",
    "                    input_example = X_test[:5] if not scipy.sparse.issparse(X_test) else X_test[:5].toarray()\n",
    "                    mlflow.sklearn.log_model(model, \"model\", input_example=input_example)\n",
    "\n",
    "                    # Printing results\n",
    "                    print(f\"\\nAlgorithm: {algo_name}\")\n",
    "                    print(f\"Metrics: {metrics}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in training {algo_name}: {e}\")\n",
    "                    mlflow.log_param(\"error\", str(e))\n",
    "\n",
    "                \n",
    "# After all models have been evaluated, logs the best model, its params and metrics\n",
    "        if best_model:\n",
    "            logging.info(f\"Best model: {best_model.__class__.__name__} with R2 score: {best_score}\")\n",
    "            mlflow.log_param(\"best_model\", best_model.__class__.__name__)\n",
    "            mlflow.log_params(best_params)\n",
    "            mlflow.log_metric(\"best_r2_score\", best_score)\n",
    "\n",
    "            # Save the best model in MLflow\n",
    "            mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "\n",
    "    logging.info(\"Training and evaluation completed.\")\n",
    "\n",
    "\n",
    "\n",
    "# ================================== LOG MODEL PARAMETERS ===========================================\n",
    "\n",
    "def log_model_params(algo_name, model):\n",
    "    \"\"\"Logs hyperparameters of the trained model to MLflow.\"\"\"\n",
    "\n",
    "    params_to_log = {}\n",
    "    if algo_name == 'LinearRegression':\n",
    "        params_to_log[\"fit_intercept\"] = model.fit_intercept\n",
    "\n",
    "    elif algo_name == 'RidgeRegression':\n",
    "        params_to_log[\"alpha\"] = model.alpha\n",
    "\n",
    "    elif algo_name == 'LassoRegression':\n",
    "        params_to_log[\"alpha\"] = model.alpha\n",
    "\n",
    "    elif algo_name == 'RandomForest':\n",
    "        params_to_log[\"n_estimators\"] = model.n_estimators\n",
    "        params_to_log[\"max_depth\"] = model.max_depth\n",
    "        params_to_log[\"min_samples_leaf\"] = model.min_samples_leaf\n",
    "\n",
    "    elif algo_name == 'XGBoost':\n",
    "        params_to_log[\"n_estimators\"] = model.get_params().get(\"n_estimators\", None)\n",
    "        params_to_log[\"learning_rate\"] = model.get_params().get(\"learning_rate\", None)\n",
    "        params_to_log[\"max_depth\"] = model.get_params().get(\"max_depth\", None)\n",
    "\n",
    "    mlflow.log_params(params_to_log)       # Logging parameters\n",
    "\n",
    "''' We needed to use .get_params() for XGBoost because XGBoost models donâ€™t always \n",
    "expose parameters as direct attributes like model.n_estimators in RandomForestRegressor. \n",
    "Instead, XGBoost stores its parameters in a dictionary, accessible via .get_params().'''\n",
    "\n",
    "\n",
    "# ========================== EXECUTION ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data(CONFIG[\"data_path\"])\n",
    "    train_and_evaluate(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
